#!/usr/bin/env python3
"""
æ•°æ®åº“æ€§èƒ½ä¼˜åŒ–æ‰§è¡Œè„šæœ¬
APIæƒé™é‡æ„é¡¹ç›® - ä»»åŠ¡3.5
åˆ›å»ºæ—¶é—´: 2025-01-10
"""

import asyncio
import asyncpg
import json
import logging
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class PerformanceOptimizationExecutor:
    """æ€§èƒ½ä¼˜åŒ–æ‰§è¡Œå™¨"""
    
    def __init__(self, database_url: str):
        self.database_url = database_url
        self.conn: Optional[asyncpg.Connection] = None
        self.execution_log = []
        
    async def connect(self):
        """è¿æ¥æ•°æ®åº“"""
        try:
            self.conn = await asyncpg.connect(self.database_url)
            logger.info("æ•°æ®åº“è¿æ¥æˆåŠŸ")
        except Exception as e:
            logger.error(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            raise
    
    async def disconnect(self):
        """æ–­å¼€æ•°æ®åº“è¿æ¥"""
        if self.conn:
            await self.conn.close()
            logger.info("æ•°æ®åº“è¿æ¥å·²æ–­å¼€")
    
    async def execute_full_optimization(self):
        """æ‰§è¡Œå®Œæ•´çš„æ€§èƒ½ä¼˜åŒ–"""
        logger.info("ğŸš€ å¼€å§‹æ‰§è¡Œæ•°æ®åº“æ€§èƒ½ä¼˜åŒ–")
        
        try:
            # 1. åˆ›å»ºæ ¸å¿ƒç´¢å¼•
            await self._execute_core_indexes()
            
            # 2. æ‰§è¡ŒæŸ¥è¯¢ä¼˜åŒ–
            await self._execute_query_optimization()
            
            # 3. è®¾ç½®ç›‘æ§
            await self._setup_monitoring()
            
            # 4. æ‰§è¡Œæ€§èƒ½æµ‹è¯•
            await self._run_performance_tests()
            
            # 5. ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š
            await self._generate_optimization_report()
            
            logger.info("âœ… æ•°æ®åº“æ€§èƒ½ä¼˜åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ æ€§èƒ½ä¼˜åŒ–æ‰§è¡Œå¤±è´¥: {e}")
            raise
    
    async def _execute_core_indexes(self):
        """æ‰§è¡Œæ ¸å¿ƒç´¢å¼•åˆ›å»º"""
        logger.info("ğŸ“Š åˆ›å»ºæƒé™æŸ¥è¯¢æ ¸å¿ƒç´¢å¼•...")
        
        # è¯»å–ç´¢å¼•åˆ›å»ºè„šæœ¬
        index_script_path = Path(__file__).parent / "performance_optimization_indexes_simple.sql"
        
        if not index_script_path.exists():
            logger.error(f"ç´¢å¼•è„šæœ¬æ–‡ä»¶ä¸å­˜åœ¨: {index_script_path}")
            return
        
        try:
            with open(index_script_path, 'r', encoding='utf-8') as f:
                index_sql = f.read()
            
            # æ‰§è¡Œç´¢å¼•åˆ›å»ºè„šæœ¬
            await self.conn.execute(index_sql)
            
            self.execution_log.append({
                'step': 'create_indexes',
                'status': 'success',
                'message': 'æ ¸å¿ƒç´¢å¼•åˆ›å»ºå®Œæˆ',
                'timestamp': datetime.now().isoformat()
            })
            
            logger.info("âœ… æ ¸å¿ƒç´¢å¼•åˆ›å»ºå®Œæˆ")
            
        except Exception as e:
            error_msg = f"ç´¢å¼•åˆ›å»ºå¤±è´¥: {e}"
            logger.error(error_msg)
            self.execution_log.append({
                'step': 'create_indexes',
                'status': 'error',
                'message': error_msg,
                'timestamp': datetime.now().isoformat()
            })
            raise
    
    async def _execute_query_optimization(self):
        """æ‰§è¡ŒæŸ¥è¯¢ä¼˜åŒ–"""
        logger.info("ğŸ” æ‰§è¡ŒæŸ¥è¯¢ä¼˜åŒ–...")
        
        # è¯»å–æŸ¥è¯¢ä¼˜åŒ–è„šæœ¬
        query_script_path = Path(__file__).parent / "performance_optimization_queries_minimal.sql"
        
        if not query_script_path.exists():
            logger.error(f"æŸ¥è¯¢ä¼˜åŒ–è„šæœ¬æ–‡ä»¶ä¸å­˜åœ¨: {query_script_path}")
            return
        
        try:
            with open(query_script_path, 'r', encoding='utf-8') as f:
                query_sql = f.read()
            
            # æ‰§è¡ŒæŸ¥è¯¢ä¼˜åŒ–è„šæœ¬
            await self.conn.execute(query_sql)
            
            self.execution_log.append({
                'step': 'optimize_queries',
                'status': 'success',
                'message': 'æŸ¥è¯¢ä¼˜åŒ–å®Œæˆ',
                'timestamp': datetime.now().isoformat()
            })
            
            logger.info("âœ… æŸ¥è¯¢ä¼˜åŒ–å®Œæˆ")
            
        except Exception as e:
            error_msg = f"æŸ¥è¯¢ä¼˜åŒ–å¤±è´¥: {e}"
            logger.error(error_msg)
            self.execution_log.append({
                'step': 'optimize_queries',
                'status': 'error',
                'message': error_msg,
                'timestamp': datetime.now().isoformat()
            })
            raise
    
    async def _setup_monitoring(self):
        """è®¾ç½®æ€§èƒ½ç›‘æ§"""
        logger.info("ğŸ“ˆ è®¾ç½®æ€§èƒ½ç›‘æ§...")
        
        try:
            # åˆ›å»ºç›‘æ§è¡¨
            await self.conn.execute("""
                CREATE TABLE IF NOT EXISTS t_sys_performance_metrics (
                    id BIGSERIAL PRIMARY KEY,
                    query_type VARCHAR(50) NOT NULL,
                    query_text TEXT,
                    execution_time_ms NUMERIC(10,3) NOT NULL,
                    rows_returned INTEGER DEFAULT 0,
                    rows_examined INTEGER DEFAULT 0,
                    index_used BOOLEAN DEFAULT FALSE,
                    user_id BIGINT,
                    api_path VARCHAR(500),
                    created_at TIMESTAMP DEFAULT NOW()
                )
            """)
            
            await self.conn.execute("""
                CREATE TABLE IF NOT EXISTS t_sys_performance_alerts (
                    id BIGSERIAL PRIMARY KEY,
                    alert_type VARCHAR(50) NOT NULL,
                    severity VARCHAR(20) NOT NULL,
                    message TEXT NOT NULL,
                    metric_value NUMERIC(15,3),
                    threshold NUMERIC(15,3),
                    is_resolved BOOLEAN DEFAULT FALSE,
                    resolved_at TIMESTAMP,
                    created_at TIMESTAMP DEFAULT NOW()
                )
            """)
            
            # åˆ›å»ºç›‘æ§ç´¢å¼•
            await self.conn.execute("""
                CREATE INDEX IF NOT EXISTS idx_performance_metrics_type_time 
                ON t_sys_performance_metrics(query_type, created_at DESC)
            """)
            
            await self.conn.execute("""
                CREATE INDEX IF NOT EXISTS idx_performance_alerts_severity_time 
                ON t_sys_performance_alerts(severity, created_at DESC) 
                WHERE is_resolved = FALSE
            """)
            
            self.execution_log.append({
                'step': 'setup_monitoring',
                'status': 'success',
                'message': 'æ€§èƒ½ç›‘æ§è®¾ç½®å®Œæˆ',
                'timestamp': datetime.now().isoformat()
            })
            
            logger.info("âœ… æ€§èƒ½ç›‘æ§è®¾ç½®å®Œæˆ")
            
        except Exception as e:
            error_msg = f"ç›‘æ§è®¾ç½®å¤±è´¥: {e}"
            logger.error(error_msg)
            self.execution_log.append({
                'step': 'setup_monitoring',
                'status': 'error',
                'message': error_msg,
                'timestamp': datetime.now().isoformat()
            })
            raise
    
    async def _run_performance_tests(self):
        """è¿è¡Œæ€§èƒ½æµ‹è¯•"""
        logger.info("ğŸ§ª è¿è¡Œæ€§èƒ½æµ‹è¯•...")
        
        try:
            # æ£€æŸ¥æƒé™éªŒè¯å‡½æ•°æ˜¯å¦å­˜åœ¨
            function_exists = await self.conn.fetchval("""
                SELECT EXISTS (
                    SELECT 1 FROM pg_proc 
                    WHERE proname = 'check_user_permission'
                )
            """)
            
            if not function_exists:
                logger.warning("æƒé™éªŒè¯å‡½æ•°ä¸å­˜åœ¨ï¼Œè·³è¿‡æ€§èƒ½æµ‹è¯•")
                return
            
            # è¿è¡Œæ€§èƒ½æµ‹è¯•
            test_results = await self.conn.fetch("""
                SELECT * FROM test_permission_query_performance(1, 100)
            """)
            
            # è®°å½•æµ‹è¯•ç»“æœ
            test_summary = {}
            for result in test_results:
                test_summary[result['test_name']] = {
                    'avg_time_ms': float(result['avg_time_ms']),
                    'min_time_ms': float(result['min_time_ms']),
                    'max_time_ms': float(result['max_time_ms']),
                    'total_time_ms': float(result['total_time_ms'])
                }
            
            self.execution_log.append({
                'step': 'performance_tests',
                'status': 'success',
                'message': 'æ€§èƒ½æµ‹è¯•å®Œæˆ',
                'test_results': test_summary,
                'timestamp': datetime.now().isoformat()
            })
            
            logger.info("âœ… æ€§èƒ½æµ‹è¯•å®Œæˆ")
            
            # è¾“å‡ºæµ‹è¯•ç»“æœ
            print("\nğŸ“Š æ€§èƒ½æµ‹è¯•ç»“æœ:")
            for test_name, metrics in test_summary.items():
                print(f"  {test_name}:")
                print(f"    å¹³å‡æ—¶é—´: {metrics['avg_time_ms']:.2f}ms")
                print(f"    æœ€å°æ—¶é—´: {metrics['min_time_ms']:.2f}ms")
                print(f"    æœ€å¤§æ—¶é—´: {metrics['max_time_ms']:.2f}ms")
            
        except Exception as e:
            error_msg = f"æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}"
            logger.error(error_msg)
            self.execution_log.append({
                'step': 'performance_tests',
                'status': 'error',
                'message': error_msg,
                'timestamp': datetime.now().isoformat()
            })
            # æ€§èƒ½æµ‹è¯•å¤±è´¥ä¸åº”è¯¥é˜»æ­¢æ•´ä¸ªä¼˜åŒ–è¿‡ç¨‹
            logger.warning("æ€§èƒ½æµ‹è¯•å¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œå…¶ä»–ä¼˜åŒ–æ­¥éª¤")
    
    async def _generate_optimization_report(self):
        """ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š"""
        logger.info("ğŸ“‹ ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š...")
        
        try:
            # æ”¶é›†ä¼˜åŒ–åçš„ç»Ÿè®¡ä¿¡æ¯
            table_stats = await self.conn.fetch("""
                SELECT 
                    tablename,
                    seq_scan,
                    seq_tup_read,
                    idx_scan,
                    idx_tup_fetch,
                    n_live_tup,
                    n_dead_tup,
                    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as table_size
                FROM pg_stat_user_tables 
                WHERE tablename IN ('t_sys_api_endpoints', 't_sys_user_permissions', 't_sys_role_permissions')
                ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC
            """)
            
            index_stats = await self.conn.fetch("""
                SELECT 
                    tablename,
                    indexname,
                    idx_scan,
                    idx_tup_read,
                    idx_tup_fetch,
                    pg_size_pretty(pg_relation_size(indexname::regclass)) as index_size
                FROM pg_stat_user_indexes 
                WHERE tablename IN ('t_sys_api_endpoints', 't_sys_user_permissions', 't_sys_role_permissions')
                ORDER BY idx_scan DESC
            """)
            
            # ç”ŸæˆæŠ¥å‘Š
            report = {
                'optimization_completed_at': datetime.now().isoformat(),
                'execution_log': self.execution_log,
                'post_optimization_stats': {
                    'table_statistics': [dict(row) for row in table_stats],
                    'index_statistics': [dict(row) for row in index_stats]
                },
                'summary': {
                    'total_steps': len(self.execution_log),
                    'successful_steps': len([log for log in self.execution_log if log['status'] == 'success']),
                    'failed_steps': len([log for log in self.execution_log if log['status'] == 'error'])
                }
            }
            
            # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
            report_dir = Path("reports")
            report_dir.mkdir(exist_ok=True)
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            report_path = report_dir / f"performance_optimization_execution_{timestamp}.json"
            
            with open(report_path, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False, default=str)
            
            logger.info(f"âœ… ä¼˜åŒ–æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
            
            # è¾“å‡ºæ‰§è¡Œæ‘˜è¦
            print(f"\nğŸ“‹ ä¼˜åŒ–æ‰§è¡Œæ‘˜è¦:")
            print(f"  æ€»æ­¥éª¤æ•°: {report['summary']['total_steps']}")
            print(f"  æˆåŠŸæ­¥éª¤: {report['summary']['successful_steps']}")
            print(f"  å¤±è´¥æ­¥éª¤: {report['summary']['failed_steps']}")
            print(f"  æŠ¥å‘Šæ–‡ä»¶: {report_path}")
            
        except Exception as e:
            error_msg = f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}"
            logger.error(error_msg)
            self.execution_log.append({
                'step': 'generate_report',
                'status': 'error',
                'message': error_msg,
                'timestamp': datetime.now().isoformat()
            })
    
    async def verify_optimization_results(self):
        """éªŒè¯ä¼˜åŒ–ç»“æœ"""
        logger.info("ğŸ” éªŒè¯ä¼˜åŒ–ç»“æœ...")
        
        try:
            # æ£€æŸ¥ç´¢å¼•æ˜¯å¦åˆ›å»ºæˆåŠŸ
            indexes = await self.conn.fetch("""
                SELECT 
                    tablename,
                    indexname,
                    indexdef
                FROM pg_indexes 
                WHERE tablename IN ('t_sys_api_endpoints', 't_sys_user_permissions', 't_sys_role_permissions')
                  AND indexname LIKE 'idx_%'
                ORDER BY tablename, indexname
            """)
            
            print(f"\nğŸ“Š ä¼˜åŒ–ç»“æœéªŒè¯:")
            print(f"  åˆ›å»ºçš„ç´¢å¼•æ•°é‡: {len(indexes)}")
            
            # æŒ‰è¡¨åˆ†ç»„æ˜¾ç¤ºç´¢å¼•
            table_indexes = {}
            for index in indexes:
                table_name = index['tablename']
                if table_name not in table_indexes:
                    table_indexes[table_name] = []
                table_indexes[table_name].append(index['indexname'])
            
            for table_name, index_list in table_indexes.items():
                print(f"  {table_name}: {len(index_list)} ä¸ªç´¢å¼•")
                for index_name in index_list:
                    print(f"    - {index_name}")
            
            # æ£€æŸ¥å‡½æ•°æ˜¯å¦åˆ›å»ºæˆåŠŸ
            functions = await self.conn.fetch("""
                SELECT 
                    proname,
                    prosrc
                FROM pg_proc 
                WHERE proname LIKE '%permission%'
                  AND proname IN ('check_user_permission', 'check_role_permission', 'check_api_permission')
            """)
            
            print(f"  åˆ›å»ºçš„å‡½æ•°æ•°é‡: {len(functions)}")
            for func in functions:
                print(f"    - {func['proname']}")
            
            # æ£€æŸ¥ç›‘æ§è¡¨æ˜¯å¦åˆ›å»ºæˆåŠŸ
            monitoring_tables = await self.conn.fetch("""
                SELECT 
                    tablename
                FROM pg_tables 
                WHERE tablename IN ('t_sys_performance_metrics', 't_sys_performance_alerts')
            """)
            
            print(f"  åˆ›å»ºçš„ç›‘æ§è¡¨æ•°é‡: {len(monitoring_tables)}")
            for table in monitoring_tables:
                print(f"    - {table['tablename']}")
            
            return True
            
        except Exception as e:
            logger.error(f"éªŒè¯ä¼˜åŒ–ç»“æœå¤±è´¥: {e}")
            return False

async def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='æ•°æ®åº“æ€§èƒ½ä¼˜åŒ–æ‰§è¡Œå™¨')
    parser.add_argument('--db-url', required=True, help='æ•°æ®åº“è¿æ¥URL')
    parser.add_argument('--action', choices=['optimize', 'verify', 'both'], 
                       default='both', help='æ‰§è¡Œçš„æ“ä½œ')
    parser.add_argument('--skip-tests', action='store_true', help='è·³è¿‡æ€§èƒ½æµ‹è¯•')
    
    args = parser.parse_args()
    
    executor = PerformanceOptimizationExecutor(args.db_url)
    
    try:
        await executor.connect()
        
        if args.action in ['optimize', 'both']:
            print("ğŸš€ å¼€å§‹æ‰§è¡Œæ•°æ®åº“æ€§èƒ½ä¼˜åŒ–...")
            await executor.execute_full_optimization()
            print("âœ… æ€§èƒ½ä¼˜åŒ–æ‰§è¡Œå®Œæˆ")
        
        if args.action in ['verify', 'both']:
            print("\nğŸ” éªŒè¯ä¼˜åŒ–ç»“æœ...")
            success = await executor.verify_optimization_results()
            if success:
                print("âœ… ä¼˜åŒ–ç»“æœéªŒè¯é€šè¿‡")
            else:
                print("âŒ ä¼˜åŒ–ç»“æœéªŒè¯å¤±è´¥")
                sys.exit(1)
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸ æ“ä½œè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        logger.error(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")
        sys.exit(1)
    finally:
        await executor.disconnect()

if __name__ == '__main__':
    asyncio.run(main())