#!/usr/bin/env python3
"""
ç«‹å³æ‰§è¡Œåˆ†é˜¶æ®µæ•°æ®åº“è¿ç§»
ä½¿ç”¨å®é™…çš„æ•°æ®åº“é…ç½®ç›´æ¥æ‰§è¡Œè¿ç§»
"""

import asyncio
import json
import logging
import os
import sys
from datetime import datetime
from pathlib import Path

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ['DATABASE_URL'] = 'postgresql://postgres:Hanatech%40123@127.0.0.1:5432/devicemonitor'

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('migration_now.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def print_banner():
    """æ‰“å°æ¨ªå¹…"""
    banner = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                 ğŸš€ APIæƒé™é‡æ„ - æ•°æ®åº“è¿ç§»                  â•‘
â•‘              API Permission Refactor Migration              â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  æ•°æ®åº“: devicemonitor                                       â•‘
â•‘  å¼€å§‹æ—¶é—´: {time}                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """.format(time=datetime.now().strftime('%Y-%m-%d %H:%M:%S'))
    print(banner)

async def test_database_connection():
    """æµ‹è¯•æ•°æ®åº“è¿æ¥"""
    logger.info("ğŸ”— æµ‹è¯•æ•°æ®åº“è¿æ¥...")
    
    try:
        import asyncpg
        
        db_url = os.environ['DATABASE_URL']
        logger.info(f"è¿æ¥åˆ°: {db_url.split('@')[1]}")
        
        conn = await asyncpg.connect(db_url)
        result = await conn.fetchval("SELECT version()")
        await conn.close()
        
        logger.info(f"âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
        logger.info(f"PostgreSQLç‰ˆæœ¬: {result.split(',')[0]}")
        return True
        
    except ImportError:
        logger.error("âŒ ç¼ºå°‘ asyncpg ä¾èµ–")
        logger.info("è¯·è¿è¡Œ: pip install asyncpg")
        return False
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        return False

async def check_existing_tables():
    """æ£€æŸ¥ç°æœ‰è¡¨ç»“æ„"""
    logger.info("ğŸ“‹ æ£€æŸ¥ç°æœ‰è¡¨ç»“æ„...")
    
    try:
        import asyncpg
        
        db_url = os.environ['DATABASE_URL']
        conn = await asyncpg.connect(db_url)
        
        # æ£€æŸ¥æºè¡¨
        tables_to_check = ['api', 'user_permissions', 'role_permissions']
        existing_tables = []
        
        for table in tables_to_check:
            result = await conn.fetchval("""
                SELECT EXISTS (
                    SELECT FROM information_schema.tables 
                    WHERE table_schema = 'public' 
                    AND table_name = $1
                )
            """, table)
            
            if result:
                count = await conn.fetchval(f"SELECT COUNT(*) FROM {table}")
                logger.info(f"âœ… è¡¨ {table} å­˜åœ¨ï¼Œè®°å½•æ•°: {count}")
                existing_tables.append(table)
            else:
                logger.warning(f"âš ï¸ è¡¨ {table} ä¸å­˜åœ¨")
        
        await conn.close()
        return existing_tables
        
    except Exception as e:
        logger.error(f"âŒ æ£€æŸ¥è¡¨ç»“æ„å¤±è´¥: {e}")
        return []

async def create_target_tables():
    """åˆ›å»ºç›®æ ‡è¡¨ç»“æ„"""
    logger.info("ğŸ—ï¸ åˆ›å»ºç›®æ ‡è¡¨ç»“æ„...")
    
    try:
        import asyncpg
        
        db_url = os.environ['DATABASE_URL']
        conn = await asyncpg.connect(db_url)
        
        # åˆ›å»ºAPIç«¯ç‚¹è¡¨
        await conn.execute("""
            CREATE TABLE IF NOT EXISTS t_sys_api_endpoints (
                id BIGSERIAL PRIMARY KEY,
                api_code VARCHAR(100) NOT NULL UNIQUE,
                api_name VARCHAR(200) NOT NULL,
                api_path VARCHAR(500) NOT NULL,
                http_method VARCHAR(10) NOT NULL,
                group_id BIGINT NOT NULL DEFAULT 1,
                description TEXT,
                version VARCHAR(10) DEFAULT 'v2',
                is_public BOOLEAN DEFAULT FALSE,
                is_deprecated BOOLEAN DEFAULT FALSE,
                rate_limit INTEGER DEFAULT 0,
                status VARCHAR(20) DEFAULT 'active',
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                
                CONSTRAINT chk_http_method CHECK (http_method IN ('GET', 'POST', 'PUT', 'PATCH', 'DELETE', 'HEAD', 'OPTIONS')),
                CONSTRAINT chk_api_endpoint_status CHECK (status IN ('active', 'inactive', 'deprecated'))
            );
        """)
        
        # åˆ›å»ºç”¨æˆ·æƒé™è¡¨
        await conn.execute("""
            CREATE TABLE IF NOT EXISTS t_sys_user_permissions (
                id BIGSERIAL PRIMARY KEY,
                user_id BIGINT NOT NULL,
                permission_code VARCHAR(255) NOT NULL,
                resource_id VARCHAR(100),
                granted_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                granted_by BIGINT,
                expires_at TIMESTAMP,
                is_active BOOLEAN DEFAULT TRUE,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                
                UNIQUE(user_id, permission_code, resource_id)
            );
        """)
        
        # åˆ›å»ºè§’è‰²æƒé™è¡¨
        await conn.execute("""
            CREATE TABLE IF NOT EXISTS t_sys_role_permissions (
                id BIGSERIAL PRIMARY KEY,
                role_id BIGINT NOT NULL,
                permission_code VARCHAR(255) NOT NULL,
                resource_type VARCHAR(100),
                is_active BOOLEAN DEFAULT TRUE,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                
                UNIQUE(role_id, permission_code, resource_type)
            );
        """)
        
        # åˆ›å»ºAPIåˆ†ç»„è¡¨
        await conn.execute("""
            CREATE TABLE IF NOT EXISTS t_sys_api_groups (
                id BIGSERIAL PRIMARY KEY,
                group_code VARCHAR(50) NOT NULL UNIQUE,
                group_name VARCHAR(100) NOT NULL,
                parent_id BIGINT DEFAULT 0,
                description TEXT,
                sort_order INTEGER DEFAULT 0,
                status VARCHAR(20) DEFAULT 'active',
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                
                CONSTRAINT chk_api_group_status CHECK (status IN ('active', 'inactive', 'deprecated'))
            );
        """)
        
        # æ’å…¥é»˜è®¤APIåˆ†ç»„
        await conn.execute("""
            INSERT INTO t_sys_api_groups (id, group_code, group_name, description, sort_order) VALUES
            (1, 'default', 'é»˜è®¤åˆ†ç»„', 'é»˜è®¤APIåˆ†ç»„', 0)
            ON CONFLICT (group_code) DO NOTHING;
        """)
        
        await conn.close()
        logger.info("âœ… ç›®æ ‡è¡¨ç»“æ„åˆ›å»ºå®Œæˆ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ åˆ›å»ºç›®æ ‡è¡¨å¤±è´¥: {e}")
        return False

async def migrate_api_data():
    """è¿ç§»APIæ•°æ®"""
    logger.info("ğŸ“Š å¼€å§‹è¿ç§»APIæ•°æ®...")
    
    try:
        import asyncpg
        
        db_url = os.environ['DATABASE_URL']
        conn = await asyncpg.connect(db_url)
        
        # æ£€æŸ¥æºè¡¨æ˜¯å¦å­˜åœ¨
        api_exists = await conn.fetchval("""
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_schema = 'public' 
                AND table_name = 'api'
            )
        """)
        
        if not api_exists:
            logger.warning("âš ï¸ æºè¡¨ 'api' ä¸å­˜åœ¨ï¼Œè·³è¿‡æ•°æ®è¿ç§»")
            await conn.close()
            return True
        
        # è·å–æºè¡¨æ•°æ®
        source_data = await conn.fetch("SELECT * FROM api LIMIT 100")
        logger.info(f"ğŸ“‹ æ‰¾åˆ° {len(source_data)} æ¡APIè®°å½•")
        
        if not source_data:
            logger.info("â„¹ï¸ æºè¡¨ä¸ºç©ºï¼Œæ— éœ€è¿ç§»æ•°æ®")
            await conn.close()
            return True
        
        # è¿ç§»æ•°æ®åˆ°ç›®æ ‡è¡¨
        migrated_count = 0
        for record in source_data:
            try:
                # æ ¹æ®å®é™…çš„æºè¡¨ç»“æ„è°ƒæ•´å­—æ®µæ˜ å°„
                api_code = record.get('code', f"api_{record.get('id', migrated_count)}")
                api_name = record.get('name', record.get('title', f"API {record.get('id', migrated_count)}"))
                api_path = record.get('path', record.get('url', f"/api/unknown/{record.get('id', migrated_count)}"))
                http_method = record.get('method', 'GET').upper()
                description = record.get('description', record.get('desc', ''))
                
                await conn.execute("""
                    INSERT INTO t_sys_api_endpoints 
                    (api_code, api_name, api_path, http_method, description, version, status)
                    VALUES ($1, $2, $3, $4, $5, 'v2', 'active')
                    ON CONFLICT (api_code) DO UPDATE SET
                        api_name = EXCLUDED.api_name,
                        api_path = EXCLUDED.api_path,
                        http_method = EXCLUDED.http_method,
                        description = EXCLUDED.description,
                        updated_at = CURRENT_TIMESTAMP
                """, api_code, api_name, api_path, http_method, description)
                
                migrated_count += 1
                
            except Exception as e:
                logger.warning(f"âš ï¸ è¿ç§»è®°å½•å¤±è´¥: {e}")
                continue
        
        await conn.close()
        logger.info(f"âœ… æˆåŠŸè¿ç§» {migrated_count} æ¡APIè®°å½•")
        return True
        
    except Exception as e:
        logger.error(f"âŒ è¿ç§»APIæ•°æ®å¤±è´¥: {e}")
        return False

async def verify_migration():
    """éªŒè¯è¿ç§»ç»“æœ"""
    logger.info("ğŸ” éªŒè¯è¿ç§»ç»“æœ...")
    
    try:
        import asyncpg
        
        db_url = os.environ['DATABASE_URL']
        conn = await asyncpg.connect(db_url)
        
        # æ£€æŸ¥ç›®æ ‡è¡¨æ•°æ®
        api_count = await conn.fetchval("SELECT COUNT(*) FROM t_sys_api_endpoints")
        user_perm_count = await conn.fetchval("SELECT COUNT(*) FROM t_sys_user_permissions")
        role_perm_count = await conn.fetchval("SELECT COUNT(*) FROM t_sys_role_permissions")
        
        logger.info(f"ğŸ“Š è¿ç§»ç»“æœç»Ÿè®¡:")
        logger.info(f"   - APIç«¯ç‚¹: {api_count} æ¡")
        logger.info(f"   - ç”¨æˆ·æƒé™: {user_perm_count} æ¡")
        logger.info(f"   - è§’è‰²æƒé™: {role_perm_count} æ¡")
        
        # æ£€æŸ¥è¡¨ç»“æ„
        tables = await conn.fetch("""
            SELECT table_name, 
                   (SELECT COUNT(*) FROM information_schema.columns 
                    WHERE table_name = t.table_name AND table_schema = 'public') as column_count
            FROM information_schema.tables t
            WHERE table_schema = 'public' 
            AND table_name LIKE 't_sys_%'
            ORDER BY table_name
        """)
        
        logger.info("ğŸ“‹ ç›®æ ‡è¡¨ç»“æ„:")
        for table in tables:
            logger.info(f"   - {table['table_name']}: {table['column_count']} åˆ—")
        
        await conn.close()
        logger.info("âœ… è¿ç§»éªŒè¯å®Œæˆ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ éªŒè¯è¿ç§»å¤±è´¥: {e}")
        return False

async def main():
    """ä¸»å‡½æ•°"""
    print_banner()
    
    try:
        # 1. æµ‹è¯•æ•°æ®åº“è¿æ¥
        if not await test_database_connection():
            logger.error("âŒ æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œè¿ç§»ç»ˆæ­¢")
            return False
        
        # 2. æ£€æŸ¥ç°æœ‰è¡¨
        existing_tables = await check_existing_tables()
        
        # 3. åˆ›å»ºç›®æ ‡è¡¨
        if not await create_target_tables():
            logger.error("âŒ åˆ›å»ºç›®æ ‡è¡¨å¤±è´¥ï¼Œè¿ç§»ç»ˆæ­¢")
            return False
        
        # 4. è¿ç§»æ•°æ®
        if 'api' in existing_tables:
            if not await migrate_api_data():
                logger.error("âŒ æ•°æ®è¿ç§»å¤±è´¥")
                return False
        else:
            logger.info("â„¹ï¸ æºè¡¨ä¸å­˜åœ¨ï¼Œè·³è¿‡æ•°æ®è¿ç§»")
        
        # 5. éªŒè¯è¿ç§»ç»“æœ
        if not await verify_migration():
            logger.error("âŒ è¿ç§»éªŒè¯å¤±è´¥")
            return False
        
        # 6. å®Œæˆ
        print("\n" + "=" * 60)
        print("ğŸ‰ APIæƒé™é‡æ„æ•°æ®åº“è¿ç§»æ‰§è¡ŒæˆåŠŸï¼")
        print("=" * 60)
        print("\nğŸ“‹ è¿ç§»å®Œæˆ:")
        print("âœ… ç›®æ ‡è¡¨ç»“æ„å·²åˆ›å»º")
        print("âœ… æ•°æ®è¿ç§»å·²å®Œæˆ")
        print("âœ… è¿ç§»ç»“æœå·²éªŒè¯")
        print("\nğŸ“„ æ—¥å¿—æ–‡ä»¶: migration_now.log")
        print("ğŸŠ æ­å–œå®ŒæˆAPIæƒé™é‡æ„è¿ç§»ï¼")
        
        return True
        
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
        return False
    except Exception as e:
        logger.error(f"ğŸ’¥ æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        print(f"\nğŸ’¥ æ‰§è¡Œå¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)